import requests
import re
import os
import time
import json
from urllib.parse import urlparse
from bs4 import BeautifulSoup
import threading
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import signal
import sys

# é»˜è®¤é…ç½®
DEFAULT_CONFIG = {
    "tags": "mightyniku video",
    "max_workers": 2
}

def get_default_download_dir():
    """æ ¹æ®é»˜è®¤é…ç½®çš„tags[0]åˆ›å»ºä¸‹è½½ç›®å½•"""
    tags = DEFAULT_CONFIG["tags"].split()
    if tags:
        first_tag = tags[0]
        download_dir = os.path.join("downloads", first_tag)
        os.makedirs(download_dir, exist_ok=True)
        return download_dir
    return "downloads"

CONFIG_FILE = "rule34_config.json"

def save_config(config):
    """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
    try:
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        print(f"âœ… é…ç½®å·²ä¿å­˜åˆ° {CONFIG_FILE}")
    except Exception as e:
        print(f"âŒ ä¿å­˜é…ç½®å¤±è´¥: {e}")

def load_config():
    """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
    try:
        if os.path.exists(CONFIG_FILE):
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                config = json.load(f)
            print(f"âœ… é…ç½®å·²ä» {CONFIG_FILE} åŠ è½½")
            return config
        else:
            print(f"âš ï¸ é…ç½®æ–‡ä»¶ {CONFIG_FILE} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return DEFAULT_CONFIG
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        return DEFAULT_CONFIG

class Rule34FixedDownloader:
    def __init__(self, max_workers=3):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        })
        
        self.lock = threading.Lock()
        self.downloaded_count = 0
        self.total_posts = 0
        self.downloaded_urls = set()  # è®°å½•å·²ä¸‹è½½çš„URLï¼Œé¿å…é‡å¤
        self.max_workers = max_workers  # å¹¶å‘çº¿ç¨‹æ•°
        
        # é‡å¤æ–‡ä»¶æ£€æµ‹
        self.downloaded_files_config = "downloaded_files_config.json"
        self.downloaded_files = self.load_downloaded_files()
        
        # å¸–å­æ£€æµ‹è®°å½•
        self.detected_posts_config = "detected_posts_config.json"
        self.detected_posts = self.load_detected_posts()
        
        # ç¨‹åºæ§åˆ¶æ ‡å¿—
        self.should_stop = False
        self.active_downloads = set()  # è®°å½•æ­£åœ¨ä¸‹è½½çš„ä»»åŠ¡
        
        # ç¼©ç•¥å›¾URLæ­£åˆ™è¡¨è¾¾å¼
        self.thumbnail_pattern = re.compile(
            r'https://wimg\.rule34\.xxx/thumbnails/(\d+)/thumbnail_([a-f0-9]+)\.jpg\?(\d+)',
            re.IGNORECASE
        )
        
        # æ³¨å†Œä¿¡å·å¤„ç†å™¨
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)
    
    def signal_handler(self, signum, frame):
        """å¤„ç†Ctrl+Cä¿¡å·ï¼Œä¼˜é›…é€€å‡º"""
        with self.lock:
            print("\nğŸ›‘ æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…é€€å‡º...")
            print(f"ğŸ“Š å½“å‰æ­£åœ¨ä¸‹è½½ {len(self.active_downloads)} ä¸ªæ–‡ä»¶")
            print(f"ğŸ“ˆ å·²å¤„ç†å¸–å­æ€»æ•°: {self.total_posts}")
            print(f"ğŸ’¾ å·²è®°å½•å¸–å­æ•°: {len(self.detected_posts)}")
            print(f"ğŸ“¥ å·²ä¸‹è½½æ–‡ä»¶æ•°: {self.downloaded_count}")
            self.should_stop = True
            
            if self.active_downloads:
                print("â³ æ­£åœ¨ä¸­æ–­å½“å‰ä¸‹è½½...")
                # ç­‰å¾…æ‰€æœ‰æ´»è·ƒä¸‹è½½å®Œæˆï¼Œä½†è®¾ç½®è¶…æ—¶
                timeout = 10  # æœ€å¤šç­‰å¾…10ç§’
                while self.active_downloads and timeout > 0:
                    time.sleep(1)
                    timeout -= 1
                    print(f"â³ è¿˜æœ‰ {len(self.active_downloads)} ä¸ªæ–‡ä»¶æ­£åœ¨ä¸‹è½½... (å‰©ä½™ {timeout} ç§’)")
                
                if self.active_downloads:
                    print(f"âš ï¸ ä»æœ‰ {len(self.active_downloads)} ä¸ªä¸‹è½½æœªå®Œæˆï¼Œå¼ºåˆ¶é€€å‡º")
                else:
                    print("âœ… æ‰€æœ‰ä¸‹è½½å·²å®Œæˆ")
            
            # ä¿å­˜å½“å‰è¿›åº¦
            self.save_detected_posts()
            print("ğŸ’¾ å·²ä¿å­˜æ£€æµ‹åˆ°çš„å¸–å­è®°å½•")
            print("ğŸ‘‹ ç¨‹åºå·²å®‰å…¨é€€å‡º")
            sys.exit(0)
    
    def load_detected_posts(self):
        """åŠ è½½å·²æ£€æµ‹çš„å¸–å­è®°å½•"""
        detected_posts = set()
        if os.path.exists(self.detected_posts_config):
            try:
                with open(self.detected_posts_config, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                    if 'posts' in config_data:
                        for post_info in config_data['posts']:
                            if 'post_id' in post_info:
                                detected_posts.add(post_info['post_id'])
                print(f"ğŸ“‹ å·²åŠ è½½ {len(detected_posts)} ä¸ªå·²æ£€æµ‹å¸–å­è®°å½•")
            except Exception as e:
                print(f"âš ï¸ è¯»å–å·²æ£€æµ‹å¸–å­è®°å½•å¤±è´¥: {e}")
        else:
            print("ğŸ“‹ æœªæ‰¾åˆ°å·²æ£€æµ‹å¸–å­è®°å½•ï¼Œå°†åˆ›å»ºæ–°è®°å½•")
        return detected_posts
    
    def save_detected_posts(self):
        """ä¿å­˜å·²æ£€æµ‹çš„å¸–å­è®°å½•åˆ°JSONé…ç½®æ–‡ä»¶"""
        try:
            # ç”Ÿæˆé…ç½®æ–‡ä»¶
            config_data = {
                "scan_time": datetime.now().isoformat(),
                "total_posts": len(self.detected_posts),
                "posts": [{"post_id": post_id} for post_id in sorted(self.detected_posts)]
            }
            
            # ä¿å­˜é…ç½®æ–‡ä»¶
            with open(self.detected_posts_config, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ å·²ä¿å­˜ {len(self.detected_posts)} ä¸ªå¸–å­è®°å½•åˆ° {self.detected_posts_config}")
        except Exception as e:
            print(f"âŒ ä¿å­˜å¸–å­è®°å½•å¤±è´¥: {e}")
    
    def is_post_detected(self, post_id):
        """æ£€æŸ¥å¸–å­æ˜¯å¦å·²æ£€æµ‹è¿‡"""
        return post_id in self.detected_posts
    
    def add_detected_post(self, post_id):
        """æ·»åŠ å·²æ£€æµ‹çš„å¸–å­åˆ°è®°å½•"""
        self.detected_posts.add(post_id)
    
    # ç§»é™¤waifu2xå¤„ç†æ–¹æ³• - å®Œå…¨è·³è¿‡å¢å¼ºç‰ˆé“¾æ¥
    
    def load_downloaded_files(self):
        """åŠ è½½å·²ä¸‹è½½æ–‡ä»¶è®°å½•"""
        downloaded_files = set()
        if os.path.exists(self.downloaded_files_config):
            try:
                with open(self.downloaded_files_config, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                    if 'files' in config_data:
                        for file_info in config_data['files']:
                            if 'filename' in file_info:
                                downloaded_files.add(file_info['filename'])
                print(f"ğŸ“‹ å·²åŠ è½½ {len(downloaded_files)} ä¸ªå·²ä¸‹è½½æ–‡ä»¶è®°å½•")
            except Exception as e:
                print(f"âš ï¸ è¯»å–å·²ä¸‹è½½æ–‡ä»¶è®°å½•å¤±è´¥: {e}")
        else:
            print("ğŸ“‹ æœªæ‰¾åˆ°å·²ä¸‹è½½æ–‡ä»¶è®°å½•ï¼Œå°†åˆ›å»ºæ–°è®°å½•")
        return downloaded_files
    
    def save_downloaded_files(self, download_dir="downloads"):
        """ä¿å­˜å·²ä¸‹è½½æ–‡ä»¶è®°å½•åˆ°JSONé…ç½®æ–‡ä»¶"""
        try:
            # æ‰«æä¸‹è½½ç›®å½•è·å–æ–‡ä»¶ä¿¡æ¯
            file_details = []
            total_size = 0
            
            for root, dirs, files in os.walk(download_dir):
                for file in files:
                    if file.lower().endswith(('.mp4', '.webm', '.avi', '.mov', '.mkv', '.flv', '.wmv')):
                        file_path = os.path.join(root, file)
                        try:
                            file_size = os.path.getsize(file_path)
                            file_mtime = os.path.getmtime(file_path)
                            current_dir = os.path.relpath(root, download_dir)
                            if current_dir == ".":
                                current_dir = "æ ¹ç›®å½•"
                            
                            file_details.append({
                                "filename": file,
                                "filepath": file_path,
                                "size": file_size,
                                "size_mb": round(file_size / (1024 * 1024), 2),
                                "modified_time": datetime.fromtimestamp(file_mtime).isoformat(),
                                "directory": current_dir,
                                "extension": os.path.splitext(file)[1].lower()
                            })
                            total_size += file_size
                        except OSError:
                            continue
            
            # æŒ‰ç›®å½•å’Œæ–‡ä»¶åæ’åº
            file_details.sort(key=lambda x: (x["directory"], x["filename"]))
            
            # ç”Ÿæˆé…ç½®æ–‡ä»¶
            config_data = {
                "scan_time": datetime.now().isoformat(),
                "download_directory": download_dir,
                "total_files": len(file_details),
                "total_size_bytes": total_size,
                "total_size_mb": round(total_size / (1024 * 1024), 2),
                "files": file_details
            }
            
            # ä¿å­˜é…ç½®æ–‡ä»¶
            with open(self.downloaded_files_config, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ å·²ä¿å­˜ {len(file_details)} ä¸ªæ–‡ä»¶è®°å½•åˆ° {self.downloaded_files_config}")
            print(f"ğŸ“Š æ€»å¤§å°: {config_data['total_size_mb']} MB")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶è®°å½•å¤±è´¥: {e}")
    
    def generate_file_list_summary(self, download_dir="downloads"):
        """ç”Ÿæˆæ–‡ä»¶åˆ—è¡¨æ‘˜è¦ä¿¡æ¯"""
        try:
            if not os.path.exists(self.downloaded_files_config):
                print("âš ï¸ æ–‡ä»¶åˆ—è¡¨é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œæ‰«æ")
                return
            
            with open(self.downloaded_files_config, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
            
            print(f"\nğŸ“‹ æ–‡ä»¶åˆ—è¡¨æ‘˜è¦:")
            print(f"   ğŸ“ æ‰«æç›®å½•: {config_data['download_directory']}")
            print(f"   ğŸ“… æ‰«ææ—¶é—´: {config_data['scan_time']}")
            print(f"   ğŸ“Š æ–‡ä»¶æ€»æ•°: {config_data['total_files']}")
            print(f"   ğŸ’¾ æ€»å¤§å°: {config_data['total_size_mb']} MB")
            
            # æŒ‰ç›®å½•ç»Ÿè®¡
            dir_stats = {}
            for file_info in config_data['files']:
                dir_name = file_info['directory']
                if dir_name not in dir_stats:
                    dir_stats[dir_name] = {'count': 0, 'size': 0}
                dir_stats[dir_name]['count'] += 1
                dir_stats[dir_name]['size'] += file_info['size']
            
            print(f"\nğŸ“ æŒ‰ç›®å½•ç»Ÿè®¡:")
            for dir_name, stats in sorted(dir_stats.items()):
                size_mb = round(stats['size'] / (1024 * 1024), 2)
                print(f"   ğŸ“ {dir_name}: {stats['count']} ä¸ªæ–‡ä»¶ ({size_mb} MB)")
            
            # æŒ‰æ‰©å±•åç»Ÿè®¡
            ext_stats = {}
            for file_info in config_data['files']:
                ext = file_info['extension']
                if ext not in ext_stats:
                    ext_stats[ext] = {'count': 0, 'size': 0}
                ext_stats[ext]['count'] += 1
                ext_stats[ext]['size'] += file_info['size']
            
            print(f"\nğŸ“„ æŒ‰æ‰©å±•åç»Ÿè®¡:")
            for ext, stats in sorted(ext_stats.items()):
                size_mb = round(stats['size'] / (1024 * 1024), 2)
                print(f"   ğŸ“„ {ext}: {stats['count']} ä¸ªæ–‡ä»¶ ({size_mb} MB)")
                
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ–‡ä»¶åˆ—è¡¨æ‘˜è¦å¤±è´¥: {e}")
    
    def is_file_downloaded(self, filename):
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ä¸‹è½½"""
        return filename in self.downloaded_files
    
    def check_file_exists_with_size(self, filename, download_dir="downloads"):
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¤§å°å¤§äº0"""
        # é¦–å…ˆæ£€æŸ¥è®°å½•
        if filename in self.downloaded_files:
            return True, "è®°å½•ä¸­å­˜åœ¨"
        
        # æ£€æŸ¥å®é™…æ–‡ä»¶
        for root, dirs, files in os.walk(download_dir):
            if filename in files:
                file_path = os.path.join(root, filename)
                try:
                    file_size = os.path.getsize(file_path)
                    if file_size > 0:
                        return True, f"æ–‡ä»¶å­˜åœ¨ ({file_size} å­—èŠ‚)"
                    else:
                        return False, "æ–‡ä»¶å¤§å°ä¸º0"
                except OSError:
                    return False, "æ— æ³•è¯»å–æ–‡ä»¶"
        
        return False, "æ–‡ä»¶ä¸å­˜åœ¨"
    
    def add_downloaded_file(self, filename):
        """æ·»åŠ å·²ä¸‹è½½æ–‡ä»¶åˆ°è®°å½•"""
        self.downloaded_files.add(filename)
    
    def find_files_by_post_id(self, post_id, download_dir="downloads"):
        """æ ¹æ®post_idæŸ¥æ‰¾å·²å­˜åœ¨çš„æ–‡ä»¶"""
        existing_files = []
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„æ–‡ä»¶
        for filename in self.downloaded_files:
            if f"_{post_id}" in filename or f"_{post_id}_" in filename:
                existing_files.append(filename)
        
        # æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿä¸­çš„æ–‡ä»¶
        if os.path.exists(download_dir):
            for root, dirs, files in os.walk(download_dir):
                for file in files:
                    if f"_{post_id}" in file or f"_{post_id}_" in file:
                        if file not in existing_files:
                            existing_files.append(file)
        
        return existing_files
    
    def sync_existing_files(self, download_dir="downloads"):
        """åŒæ­¥ç°æœ‰æ–‡ä»¶åˆ°è®°å½•ä¸­ï¼Œé€’å½’éå†æ‰€æœ‰æ–‡ä»¶å¤¹"""
        if not os.path.exists(download_dir):
            print(f"âš ï¸ ä¸‹è½½ç›®å½• {download_dir} ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºè¯¥ç›®å½•")
            os.makedirs(download_dir, exist_ok=True)
            return
        
        print(f"ğŸ” æ­£åœ¨æ‰«æ {download_dir} ç›®å½•...")
        existing_files = set()
        scanned_dirs = 0
        scanned_files = 0
        total_size = 0
        
        # é€’å½’éå†æ‰€æœ‰å­ç›®å½•
        for root, dirs, files in os.walk(download_dir):
            scanned_dirs += 1
            current_dir = os.path.relpath(root, download_dir)
            if current_dir == ".":
                current_dir = "æ ¹ç›®å½•"
            
            video_files_in_dir = []
            dir_size = 0
            for file in files:
                scanned_files += 1
                if file.lower().endswith(('.mp4', '.webm', '.avi', '.mov', '.mkv', '.flv', '.wmv')):
                    video_files_in_dir.append(file)
                    existing_files.add(file)
                    try:
                        file_size = os.path.getsize(os.path.join(root, file))
                        dir_size += file_size
                        total_size += file_size
                    except OSError:
                        continue
            
            if video_files_in_dir:
                size_mb = dir_size / (1024 * 1024)
                print(f"  ğŸ“ {current_dir}: æ‰¾åˆ° {len(video_files_in_dir)} ä¸ªè§†é¢‘æ–‡ä»¶ ({size_mb:.1f} MB)")
        
        total_size_mb = total_size / (1024 * 1024)
        print(f"ğŸ“Š æ‰«æå®Œæˆ: {scanned_dirs} ä¸ªç›®å½•, {scanned_files} ä¸ªæ–‡ä»¶, {len(existing_files)} ä¸ªè§†é¢‘æ–‡ä»¶ (æ€»è®¡ {total_size_mb:.1f} MB)")
        
        # æ£€æŸ¥è®°å½•ä¸­çš„æ–‡ä»¶æ˜¯å¦ä»ç„¶å­˜åœ¨
        missing_files = []
        for recorded_file in list(self.downloaded_files):
            if recorded_file not in existing_files:
                missing_files.append(recorded_file)
        
        # ç§»é™¤ä¸å­˜åœ¨çš„æ–‡ä»¶è®°å½•
        for missing_file in missing_files:
            self.downloaded_files.discard(missing_file)
        
        # æ·»åŠ æ–°å‘ç°çš„æ–‡ä»¶åˆ°è®°å½•ä¸­
        added_count = 0
        for filename in existing_files:
            if filename not in self.downloaded_files:
                self.downloaded_files.add(filename)
                added_count += 1
        
        if missing_files:
            print(f"ğŸ—‘ï¸ ç§»é™¤äº† {len(missing_files)} ä¸ªä¸å­˜åœ¨çš„æ–‡ä»¶è®°å½•")
        if added_count > 0:
            print(f"â• æ·»åŠ äº† {added_count} ä¸ªæ–°æ–‡ä»¶åˆ°è®°å½•ä¸­")
        
        if missing_files or added_count > 0:
            self.save_downloaded_files(download_dir)
            print(f"ğŸ’¾ å·²æ›´æ–°æ–‡ä»¶è®°å½•ï¼Œå½“å‰è®°å½• {len(self.downloaded_files)} ä¸ªæ–‡ä»¶")
        else:
            print(f"âœ… æ–‡ä»¶è®°å½•å·²æ˜¯æœ€æ–°çŠ¶æ€ï¼Œå½“å‰è®°å½• {len(self.downloaded_files)} ä¸ªæ–‡ä»¶")
    
    def cleanup_zero_size_files(self, download_dir="downloads"):
        """æ¸…ç†0å­—èŠ‚çš„æ–‡ä»¶"""
        print(f"ğŸ§¹ æ­£åœ¨æ£€æŸ¥ {download_dir} ä¸­çš„0å­—èŠ‚æ–‡ä»¶...")
        zero_size_files = []
        
        for root, dirs, files in os.walk(download_dir):
            for file in files:
                if file.lower().endswith(('.mp4', '.webm', '.avi', '.mov', '.mkv', '.flv', '.wmv')):
                    file_path = os.path.join(root, file)
                    try:
                        if os.path.getsize(file_path) == 0:
                            zero_size_files.append(file_path)
                    except OSError:
                        continue
        
        if zero_size_files:
            print(f"âš ï¸ å‘ç° {len(zero_size_files)} ä¸ª0å­—èŠ‚æ–‡ä»¶:")
            for file_path in zero_size_files:
                print(f"  ğŸ—‘ï¸ {file_path}")
            
            # è¯¢é—®æ˜¯å¦åˆ é™¤
            response = input("æ˜¯å¦åˆ é™¤è¿™äº›0å­—èŠ‚æ–‡ä»¶? (y/N): ").strip().lower()
            if response in ['y', 'yes']:
                deleted_count = 0
                for file_path in zero_size_files:
                    try:
                        os.remove(file_path)
                        filename = os.path.basename(file_path)
                        self.downloaded_files.discard(filename)  # ä»è®°å½•ä¸­ç§»é™¤
                        deleted_count += 1
                        print(f"  âœ… å·²åˆ é™¤: {file_path}")
                    except OSError as e:
                        print(f"  âŒ åˆ é™¤å¤±è´¥: {file_path} - {e}")
                
                if deleted_count > 0:
                    self.save_downloaded_files(download_dir)
                    print(f"ğŸ’¾ å·²åˆ é™¤ {deleted_count} ä¸ª0å­—èŠ‚æ–‡ä»¶å¹¶æ›´æ–°è®°å½•")
        else:
            print("âœ… æ²¡æœ‰å‘ç°0å­—èŠ‚æ–‡ä»¶")
    
    def normalize_video_url(self, url):
        """æ ‡å‡†åŒ–è§†é¢‘URLï¼Œç»Ÿä¸€åŸŸåä½†ä¸è§£æwaifu2xé“¾æ¥"""
        # ç»Ÿä¸€rule34åŸŸåï¼Œä¿ç•™æŸ¥è¯¢å‚æ•°
        parsed = urlparse(url)
        
        # ç»Ÿä¸€æ‰€æœ‰rule34å­åŸŸåä¸ºwimg.rule34.xxx
        if 'rule34.xxx' in parsed.netloc:
            netloc = 'wimg.rule34.xxx'
        else:
            netloc = parsed.netloc.replace('//', '/')
        
        # é‡æ–°æ„å»ºURLï¼Œä¿ç•™æŸ¥è¯¢å‚æ•°
        normalized = f"{parsed.scheme}://{netloc}{parsed.path}"
        if parsed.query:
            normalized += f"?{parsed.query}"
        
        print(f"ğŸ” æ ‡å‡†åŒ–URL: {url} -> {normalized}")
        return normalized
    
    # ç§»é™¤get_real_video_urlæ–¹æ³• - ä¸å†å¤„ç†waifu2xé“¾æ¥
    
    def is_valid_video_url(self, url):
        """æ£€æŸ¥URLæ˜¯å¦ä¸ºæœ‰æ•ˆçš„è§†é¢‘é“¾æ¥"""
        # å®Œå…¨æ‹’ç»waifu2xé“¾æ¥
        if 'waifu2x' in url.lower():
            return False
            
        # æ’é™¤æ— æ•ˆçš„URLåŸŸå
        invalid_domains = [
            'waifu2x.booru.pics',
            'waifu2x.udp.jp', 
            'waifu2x.0t0.nu',
            'waifu2x.c64.org'
        ]
        
        for domain in invalid_domains:
            if domain in url:
                return False
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘æ–‡ä»¶
        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm']
        return any(ext in url.lower() for ext in video_extensions)
    
    def generate_search_urls(self, tags):
        """æ ¹æ®æ ‡ç­¾ç”Ÿæˆæœç´¢URLåˆ—è¡¨ï¼Œä¸é¢„å…ˆæ£€æµ‹é¡µé¢æ•°é‡"""
        # ä¸å†é¢„å…ˆæ£€æµ‹æ‰€æœ‰é¡µé¢ï¼Œè€Œæ˜¯è¿”å›ä¸€ä¸ªç”Ÿæˆå™¨
        # è®©ä¸‹è½½è¿‡ç¨‹åŠ¨æ€æ£€æµ‹é¡µé¢
        print(f"ğŸ” å‡†å¤‡å¼€å§‹é€é¡µå¤„ç†ï¼Œæ¯é¡µ42ä¸ªå¸–å­...")
        print(f"ğŸ“‹ é¡µé¢æ•°é‡å°†åœ¨å¤„ç†è¿‡ç¨‹ä¸­åŠ¨æ€æ£€æµ‹")
        return []  # è¿”å›ç©ºåˆ—è¡¨ï¼Œè®©ä¸‹è½½è¿‡ç¨‹è‡ªå·±å¤„ç†
    
    def extract_post_ids_from_page(self, page_url, show_details=True):
        """ä»æœç´¢ç»“æœé¡µé¢æå–æ‰€æœ‰å¸–å­ID"""
        # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(0.5)
        
        # é‡è¯•æœºåˆ¶å¤„ç†429é”™è¯¯
        max_retries = 100
        for attempt in range(max_retries):
            try:
                response = self.session.get(page_url, timeout=30)
                response.raise_for_status()
                break  # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯
                
            except requests.exceptions.HTTPError as e:
                if e.response.status_code == 429:  # Too Many Requests
                    if attempt < max_retries - 1:  # ä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•
                        wait_time = 3 + attempt  # é€’å¢ç­‰å¾…æ—¶é—´ï¼š3, 4, 5, 6, 7...
                        with self.lock:
                            print(f"âš ï¸ é¡µé¢ {page_url} é‡åˆ°429é”™è¯¯ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                        time.sleep(wait_time)
                        continue
                    else:
                        with self.lock:
                            print(f"âŒ é¡µé¢ {page_url} é‡è¯• {max_retries} æ¬¡åä»ç„¶429é”™è¯¯ï¼Œè·³è¿‡")
                        return []
                else:
                    # å…¶ä»–HTTPé”™è¯¯ç›´æ¥æŠ›å‡º
                    raise
            except Exception as e:
                # éHTTPé”™è¯¯ç›´æ¥æŠ›å‡º
                raise
        
        try:
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å¸–å­ID
            post_ids = []
            
            # æ–¹æ³•1: ä»ç¼©ç•¥å›¾URLæå–ID
            thumbnail_matches = self.thumbnail_pattern.findall(response.text)
            for match in thumbnail_matches:
                folder_id, hash_id, query_id = match
                post_ids.append(query_id)
            
            # æ–¹æ³•2: ä»å¸–å­é“¾æ¥æå–ID
            post_link_pattern = r'page=post&s=view&id=(\d+)'
            link_matches = re.findall(post_link_pattern, response.text)
            post_ids.extend(link_matches)
            
            # å»é‡
            unique_post_ids = list(set(post_ids))
            
            # æ˜¾ç¤ºæ£€æµ‹è¿›åº¦ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if show_details:
                with self.lock:
                    print(f"ğŸ” é¡µé¢æ£€æµ‹å®Œæˆ: æ‰¾åˆ° {len(unique_post_ids)} ä¸ªå¸–å­ID")
                    if unique_post_ids:
                        print(f"ğŸ“‹ å¸–å­åˆ—è¡¨:")
                        for i, post_id in enumerate(unique_post_ids, 1):
                            print(f"  {i:2d}. å¸–å­ID: {post_id}")
            
            # æ³¨æ„ï¼šè¿™é‡Œä¸è®°å½•å¸–å­ï¼Œåªæœ‰åœ¨æˆåŠŸä¸‹è½½åæ‰è®°å½•
            # è®°å½•é€»è¾‘åœ¨ process_single_post æ–¹æ³•ä¸­
            
            return unique_post_ids
            
        except Exception as e:
            with self.lock:
                print(f"âŒ é¡µé¢åˆ†æå¤±è´¥: {e}")
            return []
    
    def extract_video_url_from_post(self, post_id):
        """ä»å•ä¸ªå¸–å­æå–è§†é¢‘ä¸‹è½½é“¾æ¥"""
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢
        if self.should_stop:
            return []
            
        post_url = f"https://rule34.xxx/index.php?page=post&s=view&id={post_id}"
        
        # æ·»åŠ 1ç§’å»¶è¿Ÿé¿å…429é”™è¯¯
        time.sleep(1)
        
        # é‡è¯•æœºåˆ¶å¤„ç†429é”™è¯¯
        max_retries = 100
        for attempt in range(max_retries):
            try:
                response = self.session.get(post_url, timeout=30)
                response.raise_for_status()
                break  # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯
                
            except requests.exceptions.HTTPError as e:
                if e.response.status_code == 429:  # Too Many Requests
                    if attempt < max_retries - 1:  # ä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•
                        wait_time = 3 + attempt  # é€’å¢ç­‰å¾…æ—¶é—´ï¼š3, 4, 5, 6, 7...
                        with self.lock:
                            print(f"âš ï¸ å¸–å­ {post_id} é‡åˆ°429é”™è¯¯ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                        time.sleep(wait_time)
                        continue
                    else:
                        with self.lock:
                            print(f"âŒ å¸–å­ {post_id} é‡è¯• {max_retries} æ¬¡åä»ç„¶429é”™è¯¯ï¼Œè·³è¿‡")
                        return []
                else:
                    # å…¶ä»–HTTPé”™è¯¯ç›´æ¥æŠ›å‡º
                    raise
            except Exception as e:
                # éHTTPé”™è¯¯ç›´æ¥æŠ›å‡º
                raise
        
        try:
            
            # ä½¿ç”¨BeautifulSoupè§£æHTML
            soup = BeautifulSoup(response.text, 'html.parser')
            
            video_urls = []
            processed_urls = set()  # ç”¨äºå»é‡ï¼Œå­˜å‚¨æ ‡å‡†åŒ–åçš„URL
            direct_video_urls = []  # å­˜å‚¨ç›´æ¥è§†é¢‘é“¾æ¥
            
            # ä½¿ç”¨CSSé€‰æ‹©å™¨æŸ¥æ‰¾Original imageé“¾æ¥
            original_links = soup.select('#post-view > div.sidebar > div:nth-child(6) > ul > li:nth-child(2) > a')
            
            for link in original_links:
                href = link.get('href')
                if href:
                    # å¤„ç†ç›¸å¯¹URL
                    if href.startswith('//'):
                        href = 'https:' + href
                    elif href.startswith('/'):
                        href = 'https://rule34.xxx' + href
                    
                    # æ ‡å‡†åŒ–URLå¹¶å»é‡
                    normalized_url = self.normalize_video_url(href)
                    
                    if normalized_url and normalized_url not in processed_urls:
                        if self.is_valid_video_url(href):
                            # åªå¤„ç†éwaifu2xé“¾æ¥
                            if 'waifu2x' not in href.lower():
                                direct_video_urls.append(href)
                                processed_urls.add(normalized_url)
                            else:
                                print(f"ğŸš« è·³è¿‡waifu2xå¢å¼ºç‰ˆé“¾æ¥")
                        else:
                            print(f"âŒ URLæ— æ•ˆ")
                    else:
                        print(f"âš ï¸ è·³è¿‡é‡å¤URL")
            
            # å¦‚æœé€šè¿‡"Original image"æ²¡æœ‰æ‰¾åˆ°è§†é¢‘ï¼Œå†ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾
            if not direct_video_urls:
                # åªåŒ¹é…éwaifu2xçš„.mp4é“¾æ¥
                video_pattern = r'href="((?!.*waifu2x)[^"]*\.mp4[^"]*)"'
                regex_matches = re.findall(video_pattern, response.text, re.IGNORECASE)
                for match in regex_matches:
                    if match.startswith('//'):
                        match = 'https:' + match
                    elif match.startswith('/'):
                        match = 'https://rule34.xxx' + match
                    
                    # æ ‡å‡†åŒ–URLå¹¶å»é‡
                    normalized_url = self.normalize_video_url(match)
                    
                    if normalized_url and normalized_url not in processed_urls:
                        if self.is_valid_video_url(match):
                            # åªå¤„ç†éwaifu2xé“¾æ¥
                            if 'waifu2x' not in match.lower():
                                direct_video_urls.append(match)
                                processed_urls.add(normalized_url)
                            else:
                                print(f"ğŸš« è·³è¿‡waifu2xå¢å¼ºç‰ˆé“¾æ¥")
                        else:
                            print(f"âŒ URLæ— æ•ˆ")
                    else:
                        print(f"âš ï¸ è·³è¿‡é‡å¤URL")
            
            # åªä½¿ç”¨ç›´æ¥è§†é¢‘é“¾æ¥ï¼Œå®Œå…¨è·³è¿‡waifu2xé“¾æ¥
            if direct_video_urls:
                # å¦‚æœæ‰¾åˆ°å¤šä¸ªé“¾æ¥ï¼Œåªå–ç¬¬ä¸€ä¸ªï¼ˆé¿å…é‡å¤ä¸‹è½½ï¼‰
                if len(direct_video_urls) > 1:
                    print(f"âš ï¸ å‘ç°å¤šä¸ªè§†é¢‘é“¾æ¥ï¼Œåªä¸‹è½½ç¬¬ä¸€ä¸ª")
                    video_urls = [direct_video_urls[0]]
                else:
                    video_urls = direct_video_urls
            else:
                video_urls = []
            
            with self.lock:
                if video_urls:
                    print(f"âœ… å¸–å­ {post_id} æ‰¾åˆ° {len(video_urls)} ä¸ªæœ‰æ•ˆè§†é¢‘")
                else:
                    print(f"âš ï¸ å¸–å­ {post_id} æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆè§†é¢‘")
            
            return video_urls
            
        except Exception as e:
            with self.lock:
                print(f"âŒ å¸–å­åˆ†æå¤±è´¥: {e}")
            return []
    
    def generate_unique_filename(self, video_url, post_id, download_dir):
        """ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å"""
        parsed_url = urlparse(video_url)
        original_filename = os.path.basename(parsed_url.path)
        
        # å¦‚æœæ²¡æœ‰æ‰©å±•åï¼Œæ·»åŠ .mp4
        if not original_filename.endswith(('.mp4', '.avi', '.mov', '.mkv', '.webm')):
            original_filename = f"video_{post_id}.mp4"
        
        # æå–æ–‡ä»¶åå’Œæ‰©å±•å
        name, ext = os.path.splitext(original_filename)
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å - ä½¿ç”¨hashæ ¼å¼åŒ¹é…é…ç½®æ–‡ä»¶ä¸­çš„å‘½åè§„åˆ™
        # ä»URLä¸­æå–hashéƒ¨åˆ†ï¼ˆå¦‚æœå­˜åœ¨ï¼‰æˆ–ä½¿ç”¨åŸå§‹æ–‡ä»¶å
        if '_' in name and len(name.split('_')[0]) == 32:  # 32ä½hashæ ¼å¼
            hash_part = name.split('_')[0]
            filename = f"{hash_part}_{post_id}{ext}"
        else:
            # å¦‚æœæ²¡æœ‰hashæ ¼å¼ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶å
            filename = f"{name}_{post_id}{ext}"
        
        filepath = os.path.join(download_dir, filename)
        
        # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åœ¨é…ç½®æ–‡ä»¶ä¸­å·²å­˜åœ¨æˆ–æ–‡ä»¶ç³»ç»Ÿä¸­å·²å­˜åœ¨
        counter = 1
        while self.is_file_downloaded(filename) or os.path.exists(filepath):
            if '_' in name and len(name.split('_')[0]) == 32:
                hash_part = name.split('_')[0]
                # ä½¿ç”¨æ›´æ˜ç¡®çš„é‡å¤æ–‡ä»¶æ ‡è¯†ï¼Œé¿å…ä¸post_idæ··æ·†
                filename = f"{hash_part}_{post_id}_duplicate_{counter}{ext}"
            else:
                filename = f"{name}_{post_id}_duplicate_{counter}{ext}"
            filepath = os.path.join(download_dir, filename)
            counter += 1
        
        return filepath
    
    def download_video(self, video_url, post_id, download_dir="downloads"):
        """ä¸‹è½½å•ä¸ªè§†é¢‘æ–‡ä»¶"""
        try:
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢
            if self.should_stop:
                return None
                
            # æ£€æŸ¥æ˜¯å¦å·²ç»ä¸‹è½½è¿‡è¿™ä¸ªURL
            with self.lock:
                if video_url in self.downloaded_urls:
                    print(f"âš ï¸ URLå·²ä¸‹è½½è¿‡ï¼Œè·³è¿‡")
                    return None
                    
                print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½å¸–å­ {post_id}")
                # è®°å½•æ´»è·ƒä¸‹è½½ä»»åŠ¡
                self.active_downloads.add(f"{post_id}_{video_url}")
            
            # åˆ›å»ºä¸‹è½½ç›®å½•
            os.makedirs(download_dir, exist_ok=True)
            
            # å…ˆæ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ç›¸åŒpost_idçš„æ–‡ä»¶å­˜åœ¨
            existing_files = self.find_files_by_post_id(post_id, download_dir)
            if existing_files:
                print(f"âš ï¸ å¸–å­ {post_id} çš„æ–‡ä»¶å·²å­˜åœ¨: {existing_files[0]}ï¼Œè·³è¿‡ä¸‹è½½")
                return None
            
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            filepath = self.generate_unique_filename(video_url, post_id, download_dir)
            filename = os.path.basename(filepath)
            
            # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶åæ˜¯å¦ä¸å·²å­˜åœ¨çš„æ–‡ä»¶é‡å¤
            if self.is_file_downloaded(filename):
                print(f"âš ï¸ æ–‡ä»¶ {filename} åœ¨é…ç½®æ–‡ä»¶ä¸­å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
                return None
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ä¸‹è½½è¿‡ï¼ˆåŒ…æ‹¬æ–‡ä»¶å¤§å°æ£€æŸ¥ï¼‰
            exists, reason = self.check_file_exists_with_size(filename, download_dir)
            if exists:
                print(f"âš ï¸ æ–‡ä»¶ {filename} å·²ä¸‹è½½è¿‡ ({reason})ï¼Œè·³è¿‡")
                return None
            
            # ä¸‹è½½æ–‡ä»¶
            response = self.session.get(video_url, stream=True, timeout=60)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            downloaded_size = 0
            
            with open(filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢
                    if self.should_stop:
                        print(f"\nğŸ›‘ æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œä¸­æ–­ä¸‹è½½: {filename}")
                        # ç§»é™¤æ´»è·ƒä¸‹è½½ä»»åŠ¡
                        with self.lock:
                            self.active_downloads.discard(f"{post_id}_{video_url}")
                        return None
                    
                    if chunk:
                        f.write(chunk)
                        downloaded_size += len(chunk)
                        
                        if total_size > 0:
                            progress = (downloaded_size / total_size) * 100
                            with self.lock:
                                print(f"\rğŸ“Š ä¸‹è½½è¿›åº¦: {progress:.1f}% ({downloaded_size}/{total_size} å­—èŠ‚)", end='')
            
            with self.lock:
                print(f"\nâœ… ä¸‹è½½å®Œæˆ: {filename}")
                self.downloaded_count += 1
                self.downloaded_urls.add(video_url)  # è®°å½•URLé¿å…é‡å¤
                self.add_downloaded_file(filename)  # æ·»åŠ æ–‡ä»¶åˆ°è®°å½•
                # ç§»é™¤æ´»è·ƒä¸‹è½½ä»»åŠ¡
                self.active_downloads.discard(f"{post_id}_{video_url}")
            
            return filepath
            
        except Exception as e:
            with self.lock:
                print(f"\nâŒ ä¸‹è½½å¤±è´¥: {e}")
                # ç§»é™¤æ´»è·ƒä¸‹è½½ä»»åŠ¡
                self.active_downloads.discard(f"{post_id}_{video_url}")
            return None
    
    def process_single_post(self, post_id, download_dir="downloads"):
        """å¤„ç†å•ä¸ªå¸–å­"""
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢
        if self.should_stop:
            return []
            
        with self.lock:
            print(f"ğŸ”„ å¼€å§‹å¤„ç†å¸–å­ {post_id}...")
        
        video_urls = self.extract_video_url_from_post(post_id)
        downloaded_files = []
        processed_successfully = False
        
        for video_url in video_urls:
            filepath = self.download_video(video_url, post_id, download_dir)
            if filepath:
                downloaded_files.append(filepath)
                processed_successfully = True
            else:
                # å³ä½¿æ–‡ä»¶å·²å­˜åœ¨ï¼Œä¹Ÿç®—å¤„ç†æˆåŠŸ
                processed_successfully = True
            time.sleep(3)  # æ¯ä¸ªè§†é¢‘é—´éš”3ç§’
        
        # æ— è®ºæ˜¯å¦ä¸‹è½½æ–°æ–‡ä»¶ï¼Œéƒ½è®°å½•å¸–å­ä¸ºå·²å¤„ç†
        if processed_successfully:
            self.add_detected_post(post_id)
            if downloaded_files:
                print(f"âœ… å¸–å­ {post_id} ä¸‹è½½æˆåŠŸï¼Œå·²è®°å½•")
            else:
                print(f"âœ… å¸–å­ {post_id} æ–‡ä»¶å·²å­˜åœ¨ï¼Œå·²è®°å½•")
        else:
            print(f"âš ï¸ å¸–å­ {post_id} æ— æœ‰æ•ˆè§†é¢‘ï¼Œæœªè®°å½•")
        
        return downloaded_files
    
    def download_videos_by_tags(self, tags, download_dir="downloads"):
        """æ ¹æ®æ ‡ç­¾ä¸‹è½½è§†é¢‘ï¼Œé€é¡µå¤„ç†ï¼šæ£€æµ‹ä¸€é¡µâ†’ä¸‹è½½ä¸€é¡µâ†’è®°å½•â†’ä¸‹ä¸€é¡µ"""
        print("ğŸš€ Rule34 ä¿®å¤ç‰ˆè§†é¢‘ä¸‹è½½å™¨")
        print("="*80)
        print(f"ğŸ·ï¸ æœç´¢æ ‡ç­¾: {tags}")
        print(f"ğŸ“„ é¡µæ•°: åŠ¨æ€æ£€æµ‹")
        print(f"ğŸ§µ å¹¶å‘çº¿ç¨‹æ•°: {self.max_workers}")
        print(f"ğŸ“¦ å¤„ç†æ¨¡å¼: é€é¡µå¤„ç†")
        print("="*80)
        
        # åˆå§‹åŒ–é¡µé¢å‚æ•°
        page_num = 1
        pid = 0
        
        all_downloaded_files = []
        total_processed_posts = 0
        
        # é€é¡µå¤„ç†ï¼šæ£€æµ‹ä¸€é¡µï¼Œä¸‹è½½ä¸€é¡µ
        while True:
            if self.should_stop:
                print("\nğŸ›‘ æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œåœæ­¢å¤„ç†...")
                break
            
            print(f"\nğŸ”„ å¼€å§‹å¤„ç†ç¬¬ {page_num} é¡µ")
            print("="*60)
            
            # æ„å»ºå½“å‰é¡µURL
            page_url = f"https://rule34.xxx/index.php?page=post&s=list&tags={tags}&pid={pid}"
            print(f"ğŸ”— URL: {page_url}")
            
            # æ­¥éª¤1: æ£€æµ‹å½“å‰é¡µçš„å¸–å­ID
            print(f"ğŸ” æ­¥éª¤1: æ£€æµ‹ç¬¬ {page_num} é¡µçš„å¸–å­...")
            page_post_ids = self.extract_post_ids_from_page(page_url, show_details=True)
            
            if not page_post_ids:
                print(f"ğŸ“„ ç¬¬ {page_num} é¡µæ²¡æœ‰æ‰¾åˆ°å†…å®¹ï¼Œåœæ­¢æœç´¢")
                break
            
            # è¿‡æ»¤æ‰å·²æ£€æµ‹çš„å¸–å­
            new_post_ids = [post_id for post_id in page_post_ids if post_id not in self.detected_posts]
            
            print(f"ğŸ“‹ ç¬¬ {page_num} é¡µæ£€æµ‹åˆ° {len(page_post_ids)} ä¸ªå¸–å­")
            print(f"ğŸ†• å…¶ä¸­ {len(new_post_ids)} ä¸ªæ–°å¸–å­éœ€è¦å¤„ç†")
            print(f"â­ï¸ è·³è¿‡å·²æ£€æµ‹: {len(page_post_ids) - len(new_post_ids)} ä¸ª")
            
            if not new_post_ids:
                print(f"â­ï¸ ç¬¬ {page_num} é¡µæ— æ–°å¸–å­ï¼Œè·³è¿‡")
                # ç»§ç»­ä¸‹ä¸€é¡µ
                page_num += 1
                pid += 42
                time.sleep(5)  # ä¿æŒé—´éš”
                continue
            
            # æ­¥éª¤2: ä¸‹è½½å½“å‰é¡µçš„æ‰€æœ‰å¸–å­
            print(f"ğŸ“¥ æ­¥éª¤2: ä¸‹è½½ç¬¬ {page_num} é¡µçš„å¸–å­...")
            page_downloaded_files = []
            page_processed_posts = 0
            
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                # æäº¤å½“å‰é¡µçš„ä»»åŠ¡
                future_to_post = {
                    executor.submit(self.process_single_post, post_id, download_dir): post_id 
                    for post_id in new_post_ids
                }
                
                # å¤„ç†å®Œæˆçš„ä»»åŠ¡
                try:
                    for future in as_completed(future_to_post, timeout=1):
                        # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢
                        if self.should_stop:
                            print("\nğŸ›‘ æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œå–æ¶ˆå‰©ä½™ä»»åŠ¡...")
                            # å–æ¶ˆæ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡
                            for f in future_to_post:
                                f.cancel()
                            break
                            
                        post_id = future_to_post[future]
                        try:
                            downloaded_files = future.result()
                            if downloaded_files:  # åªæœ‰æˆåŠŸä¸‹è½½æ–°æ–‡ä»¶æ‰è®¡æ•°
                                page_downloaded_files.extend(downloaded_files)
                            
                            # æ— è®ºæ˜¯å¦ä¸‹è½½æ–°æ–‡ä»¶ï¼Œéƒ½ç®—å¤„ç†äº†ä¸€ä¸ªå¸–å­
                            page_processed_posts += 1
                            
                            # è¿›åº¦åŸºäºå·²å¤„ç†çš„å¸–å­æ•°é‡
                            progress = (page_processed_posts / len(new_post_ids)) * 100
                            
                            with self.lock:
                                print(f"ğŸ“ˆ é¡µé¢è¿›åº¦: {progress:.1f}% ({page_processed_posts}/{len(new_post_ids)}) - å¸–å­ {post_id}")
                                
                        except Exception as e:
                            with self.lock:
                                print(f"âŒ å¤„ç†å¸–å­ {post_id} æ—¶å‡ºé”™: {e}")
                except TimeoutError:
                    # è¶…æ—¶æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢
                    if self.should_stop:
                        print("\nğŸ›‘ æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œå–æ¶ˆå‰©ä½™ä»»åŠ¡...")
                        for f in future_to_post:
                            f.cancel()
                        break
            
            # æ­¥éª¤3: é¡µé¢å®Œæˆæ£€æŸ¥
            print(f"ğŸ’¾ æ­¥éª¤3: æ£€æŸ¥ç¬¬ {page_num} é¡µå®Œæˆæƒ…å†µ...")
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å¸–å­éƒ½å¤„ç†å®Œæˆ
            remaining_posts = [post_id for post_id in page_post_ids if post_id not in self.detected_posts]
            
            if remaining_posts:
                print(f"âš ï¸ ç¬¬ {page_num} é¡µè¿˜æœ‰ {len(remaining_posts)} ä¸ªå¸–å­æœªå®Œæˆ:")
                for post_id in remaining_posts:
                    print(f"  - å¸–å­ID: {post_id}")
                print(f"ğŸ’¾ ä¿å­˜å½“å‰è¿›åº¦ï¼Œä¸‹æ¬¡è¿è¡Œå°†ä»ç¬¬ {page_num} é¡µç»§ç»­...")
                # ä¿å­˜å½“å‰è¿›åº¦å¹¶åœæ­¢
                self.save_detected_posts()
                break
            else:
                print(f"âœ… ç¬¬ {page_num} é¡µæ‰€æœ‰å¸–å­å¤„ç†å®Œæˆ!")
                all_downloaded_files.extend(page_downloaded_files)
                total_processed_posts += page_processed_posts
            
            print(f"\nğŸ“Š ç¬¬ {page_num} é¡µç»Ÿè®¡:")
            print(f"  æ€»å¸–å­æ•°: {len(page_post_ids)}")
            print(f"  å·²å¤„ç†: {len(page_post_ids) - len(remaining_posts)}")
            print(f"  å‰©ä½™: {len(remaining_posts)}")
            print(f"  ä¸‹è½½æ–‡ä»¶: {len(page_downloaded_files)}")
            print(f"  ç´¯è®¡å¤„ç†: {total_processed_posts}")
            print(f"  ç´¯è®¡ä¸‹è½½: {len(all_downloaded_files)}")
            
            # ä¿å­˜å½“å‰è¿›åº¦
            self.save_detected_posts()
            
            # å‡†å¤‡ä¸‹ä¸€é¡µ
            page_num += 1
            pid += 42
            
            # é¡µé¢é—´éš”
            print(f"â³ ç­‰å¾…5ç§’åå¤„ç†ä¸‹ä¸€é¡µ...")
            time.sleep(5)
        
        self.total_posts = total_processed_posts
        return all_downloaded_files
    
    def save_results(self, downloaded_files, tags, filename="download_results.json"):
        """ä¿å­˜ä¸‹è½½ç»“æœ"""
        data = {
            'download_time': time.strftime("%Y-%m-%d %H:%M:%S"),
            'tags': tags,
            'total_posts': self.total_posts,
            'downloaded_count': self.downloaded_count,
            'downloaded_files': downloaded_files
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")
    
    def print_duplicate_check_info(self):
        """æ‰“å°é‡å¤æ–‡ä»¶æ£€æŸ¥ä¿¡æ¯"""
        print(f"\nğŸ“‹ é‡å¤æ–‡ä»¶æ£€æŸ¥ä¿¡æ¯:")
        print(f"   ğŸ“ é…ç½®æ–‡ä»¶ä¸­è®°å½•çš„æ–‡ä»¶æ•°: {len(self.downloaded_files)}")
        print(f"   ğŸ” å·²åŠ è½½çš„é‡å¤æ–‡ä»¶è®°å½•: {len(self.downloaded_files)} ä¸ª")
        if self.downloaded_files:
            print(f"   ğŸ“ ç¤ºä¾‹æ–‡ä»¶å: {list(self.downloaded_files)[:3]}...")
        print("="*50)

    def print_final_statistics(self, downloaded_files, tags):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*80)
        print("ğŸ“Š æœ€ç»ˆç»Ÿè®¡")
        print("="*80)
        print(f"ğŸ·ï¸ æœç´¢æ ‡ç­¾: {tags}")
        print(f"ğŸ“‹ æ€»å¸–å­æ•°: {self.total_posts}")
        print(f"ğŸ“¥ ä¸‹è½½æˆåŠŸ: {len(downloaded_files)}")
        print(f"âŒ ä¸‹è½½å¤±è´¥: {self.total_posts - len(downloaded_files)}")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {(len(downloaded_files)/self.total_posts*100):.1f}%" if self.total_posts > 0 else "0%")
        print(f"ğŸ”„ é‡å¤æ–‡ä»¶æ£€æŸ¥: å·²è·³è¿‡ {len(self.downloaded_files)} ä¸ªå·²å­˜åœ¨çš„æ–‡ä»¶")
        
        if downloaded_files:
            print(f"\nğŸ“ ä¸‹è½½çš„æ–‡ä»¶:")
            for i, filepath in enumerate(downloaded_files, 1):
                print(f"  {i:2d}. {filepath}")
        
        print("="*80)

def get_user_input():
    """è·å–ç”¨æˆ·è¾“å…¥ - æ”¯æŒé…ç½®é€‰æ‹©"""
    print("ğŸš€ Rule34 ä¿®å¤ç‰ˆè§†é¢‘ä¸‹è½½å™¨")
    print("="*50)
    
    # é…ç½®é€‰æ‹©
    print("âš™ï¸ é…ç½®é€‰æ‹©:")
    print("   1 - ä½¿ç”¨é»˜è®¤é…ç½®")
    print("   0 - æ‰‹åŠ¨è¾“å…¥é…ç½®")
    
    while True:
        choice = input("ğŸ”§ è¯·é€‰æ‹© (1/0): ").strip()
        if choice in ['1', '0']:
            break
        print("âŒ è¯·è¾“å…¥ 1 æˆ– 0!")
    
    if choice == '1':
        # ä½¿ç”¨é»˜è®¤é…ç½®
        config = load_config()
        tags_input = config['tags']
        max_workers = config['max_workers']
        
        print(f"âœ… ä½¿ç”¨é…ç½®:")
        print(f"   ğŸ·ï¸ æ ‡ç­¾: {tags_input}")
        print(f"   ğŸ§µ çº¿ç¨‹æ•°: {max_workers}")
        print(f"   ğŸ“„ é¡µæ•°: è‡ªåŠ¨æ£€æµ‹")
        
        # å¤„ç†æ ‡ç­¾æ ¼å¼
        tag_list = [tag.strip() for tag in tags_input.split() if tag.strip()]
        tags = '+'.join(tag_list)
        
        return tags, max_workers
    
    else:
        # æ‰‹åŠ¨è¾“å…¥é…ç½®
        print("\nğŸ“ è¯·è¾“å…¥æœç´¢æ ‡ç­¾:")
        print("   ç¤ºä¾‹: test1 test2 æˆ– 2futas video")
        print("   å¤šä¸ªæ ‡ç­¾ç”¨ç©ºæ ¼åˆ†éš”")
        tags_input = input("ğŸ·ï¸ æ ‡ç­¾: ").strip()
        
        if not tags_input:
            print("âŒ æ ‡ç­¾ä¸èƒ½ä¸ºç©º!")
            return None, None
        
        # å¤„ç†æ ‡ç­¾æ ¼å¼ - ç”¨ç©ºæ ¼åˆ†éš”
        tag_list = [tag.strip() for tag in tags_input.split() if tag.strip()]
        tags = '+'.join(tag_list)
        
        print(f"âœ… å¤„ç†åçš„æ ‡ç­¾: {tags}")
        
        # è·å–çº¿ç¨‹æ•°è¾“å…¥
        print("\nğŸ§µ è¯·è¾“å…¥å¹¶å‘çº¿ç¨‹æ•°:")
        print("   ç¤ºä¾‹: 3 (æ¨è3-5ä¸ªçº¿ç¨‹)")
        print("   æ³¨æ„: çº¿ç¨‹æ•°è¿‡å¤šå¯èƒ½å¯¼è‡´è¯·æ±‚è¿‡å¿«è¢«é™åˆ¶")
        try:
            max_workers = int(input("ğŸ§µ çº¿ç¨‹æ•°: ").strip())
            if max_workers <= 0:
                print("âŒ çº¿ç¨‹æ•°å¿…é¡»å¤§äº0!")
                return None, None
            if max_workers > 10:
                print("âš ï¸ è­¦å‘Š: çº¿ç¨‹æ•°è¿‡å¤šå¯èƒ½å¯¼è‡´è¯·æ±‚è¿‡å¿«è¢«é™åˆ¶!")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—!")
            return None, None
        
        print(f"âœ… å°†è‡ªåŠ¨æ£€æµ‹é¡µé¢æ•°é‡ï¼Œä½¿ç”¨ {max_workers} ä¸ªå¹¶å‘çº¿ç¨‹")
        
        # è¯¢é—®æ˜¯å¦ä¿å­˜ä¸ºé»˜è®¤é…ç½®
        print("\nğŸ’¾ æ˜¯å¦ä¿å­˜å½“å‰é…ç½®ä¸ºé»˜è®¤é…ç½®?")
        save_choice = input("ğŸ’¾ ä¿å­˜é…ç½®? (y/n): ").strip().lower()
        if save_choice in ['y', 'yes', 'æ˜¯']:
            config = {
                "tags": tags_input,
                "max_workers": max_workers
            }
            save_config(config)
        
        return tags, max_workers

def main():
    print("ğŸš€ Rule34 ä¿®å¤ç‰ˆè§†é¢‘ä¸‹è½½å™¨")
    print("="*80)
    
    # æ ¹æ®é»˜è®¤é…ç½®çš„tags[0]åˆ›å»ºä¸‹è½½ç›®å½•
    download_dir = get_default_download_dir()
    print(f"ğŸ“ ä½¿ç”¨ä¸‹è½½ç›®å½•: {download_dir}")
    
    # åˆ›å»ºä¸‹è½½å™¨
    downloader = Rule34FixedDownloader(max_workers=1)  # å…ˆåˆ›å»ºé»˜è®¤ä¸‹è½½å™¨ç”¨äºæ‰«æ
    
    # è‡ªåŠ¨æ‰«æä¸‹è½½æ–‡ä»¶å¤¹å¹¶ç”Ÿæˆæ–‡ä»¶åˆ—è¡¨
    print(f"ğŸ“ æ­£åœ¨è‡ªåŠ¨æ‰«æ {download_dir} æ–‡ä»¶å¤¹...")
    downloader.sync_existing_files(download_dir)
    
    # ç”Ÿæˆå¹¶ä¿å­˜æ–‡ä»¶åˆ—è¡¨ JSON
    print("ğŸ’¾ æ­£åœ¨ç”Ÿæˆæ–‡ä»¶åˆ—è¡¨ JSON...")
    downloader.save_downloaded_files(download_dir)
    
    # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨æ‘˜è¦
    downloader.generate_file_list_summary(download_dir)
    
    # æ˜¾ç¤ºé‡å¤æ–‡ä»¶æ£€æŸ¥ä¿¡æ¯
    downloader.print_duplicate_check_info()
    
    # æ¸…ç†0å­—èŠ‚æ–‡ä»¶
    print("\nğŸ§¹ æ£€æŸ¥0å­—èŠ‚æ–‡ä»¶...")
    downloader.cleanup_zero_size_files(download_dir)
    
    # è·å–ç”¨æˆ·è¾“å…¥
    tags, max_workers = get_user_input()
    
    if tags is None or max_workers is None:
        print("âŒ è¾“å…¥æ— æ•ˆï¼Œç¨‹åºé€€å‡º")
        return
    
    # é‡æ–°åˆ›å»ºä¸‹è½½å™¨ï¼ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„çº¿ç¨‹æ•°ï¼‰
    downloader = Rule34FixedDownloader(max_workers=max_workers)
    
    # é‡æ–°åŠ è½½æ–‡ä»¶è®°å½•ï¼ˆç¡®ä¿ä½¿ç”¨æœ€æ–°çš„æ‰«æç»“æœï¼‰
    downloader.downloaded_files = downloader.load_downloaded_files()
    
    # å¼€å§‹ä¸‹è½½
    downloaded_files = downloader.download_videos_by_tags(tags, download_dir)
    
    # ä¿å­˜æ–‡ä»¶è®°å½•ï¼ˆæ›´æ–°åçš„ï¼‰
    downloader.save_downloaded_files(download_dir)
    
    # ä¿å­˜å¸–å­æ£€æµ‹è®°å½•
    downloader.save_detected_posts()
    
    # ä¿å­˜ç»“æœ
    downloader.save_results(downloaded_files, tags)
    
    # æ‰“å°ç»Ÿè®¡
    downloader.print_final_statistics(downloaded_files, tags)
    
    if downloaded_files:
        print(f"\nğŸ‰ ä¸‹è½½å®Œæˆ! å…±ä¸‹è½½ {len(downloaded_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
    else:
        print("âŒ æ²¡æœ‰æˆåŠŸä¸‹è½½ä»»ä½•æ–‡ä»¶")

if __name__ == "__main__":
    main()
